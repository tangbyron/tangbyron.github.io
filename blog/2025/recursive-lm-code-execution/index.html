<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Recursive Language Models + Code Execution: 60% accuracy on BrowseComp Plus (no embeddings) | Blog on AI Eng </title> <meta name="author" content="Byron Tang"> <meta name="description" content="Capturing learnings from papers and experiments. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://tangbyron.github.io/blog/2025/recursive-lm-code-execution/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Blog on AI Eng </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Recursive Language Models + Code Execution: 60% accuracy on BrowseComp Plus (no embeddings)</h1> <p class="post-meta"> Created on November 22, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/llm"> <i class="fa-solid fa-hashtag fa-sm"></i> llm</a>   <a href="/blog/tag/code-execution"> <i class="fa-solid fa-hashtag fa-sm"></i> code-execution</a>   <a href="/blog/tag/multi-hop"> <i class="fa-solid fa-hashtag fa-sm"></i> multi-hop</a>   <a href="/blog/tag/browsecomp"> <i class="fa-solid fa-hashtag fa-sm"></i> browsecomp</a>   <a href="/blog/tag/rlm"> <i class="fa-solid fa-hashtag fa-sm"></i> rlm</a>   ·   <a href="/blog/category/search"> <i class="fa-solid fa-tag fa-sm"></i> Search</a>   <a href="/blog/category/reasoning"> <i class="fa-solid fa-tag fa-sm"></i> Reasoning</a>   <a href="/blog/category/code-execution"> <i class="fa-solid fa-tag fa-sm"></i> Code Execution</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><em>This is Part 3 in an ongoing series on continual learning for LLM agents: from <a href="https://tangbyron.github.io/posts/anti-patterns-as-guardrails/">Reasoning Banks</a> → <a href="https://tangbyron.github.io/posts/recursive-language-models/">Recursive Language Models</a> → RLM + Code Execution.</em></p> <p><img src="/assets/img/posts/2025-11-22-recursive-lm-code-execution.jpg" alt="RLM + Code Execution Overview"> <em>Visual summary of the architecture and key code patterns</em></p> <h2 id="main-takeaway">Main takeaway</h2> <p>Combining Code Execution with Recursive Language Models (RLM) achieved <strong>60% accuracy</strong> on <a href="https://arxiv.org/abs/2508.06600" rel="external nofollow noopener" target="_blank">BrowseComp Plus</a> in small-scale experiments with Gemini 2.5 Flash, all without using embeddings. This is a 6X improvement compared to using the ReAct agent design, and is in the same ballpark as the BM25 only configurations of o3 and GPT-5 on the public <a href="https://huggingface.co/spaces/Tevatron/BrowseComp-Plus" rel="external nofollow noopener" target="_blank">leaderboard</a>. I want to emphasize that these are still just directionally correct early findings, since I’m running on small sample sizes. Given the costly nature of testing various experiments (lots of tokens!), I prioritized rapid architecture experimentation, vs running on the entire corpus.</p> <p>The breakthrough was letting the Root-LM write python code to programmatically chain search tools, create complex filters, and parallelize search. The Root-LM was quite creative, and often created logic that would have taken 3-4 iterations in the traditional LLM&lt;&gt;Tool loop. Code execution often resulted in huge outputs, which paired extremely well with the RLM Sub-LM summarizer that prevents context rot.</p> <p>I intentionally skipped adding in semantic search tools leveraging embeddings, since real-world scenarios are often dynamic. Users can upload new documents, ask the agent to search online, or work with constantly changing corpora. Pre-building vector stores isn’t always feasible. (On the flip side, I also don’t quite believe that “grep is all you need”, hybrid search wins for real-world use cases.)</p> <p>The journey: 0% (single BM25 search + LLM) -&gt; 10% (ReAct + BM25) -&gt; 25% (RLM + BM25) -&gt; 40% (RLM + more search tools) -&gt; 60% (RLM + search tools + code execution)</p> <hr> <h2 id="0-to-60">0 to 60</h2> <p>Building on my <a href="https://tangbyron.github.io/posts/recursive-language-models/">previous post on Recursive Language Models</a>, here’s the progression:</p> <table> <thead> <tr> <th>Variant</th> <th>Accuracy (approx)</th> </tr> </thead> <tbody> <tr> <td>Single BM25</td> <td>0%</td> </tr> <tr> <td>ReAct</td> <td>10%</td> </tr> <tr> <td>RLM + BM25</td> <td>25%</td> </tr> <tr> <td>RLM + BM25 + Regex and Keyword Scan</td> <td>35–40%</td> </tr> <tr> <td>RLM + BM25 + Regex and Keyword Scan + Code Execution</td> <td>60%</td> </tr> </tbody> </table> <hr> <h2 id="code-execution">Code Execution</h2> <h3 id="motivation">Motivation</h3> <p>As <a href="https://www.anthropic.com/engineering/code-execution-with-mcp" rel="external nofollow noopener" target="_blank">Anthropic notes</a>, adding more specialized tools creates cognitive overhead for the LLM. Each tool needs its own schema, parameters, and usage patterns to be encoded into the prompts. Even with just three search tools, it got messy real fast. Code execution was much more elegant.</p> <p>The Root-LM got a sandboxed Python environment with:</p> <ul> <li> <strong>Full Python standard library</strong>: <code class="language-plaintext highlighter-rouge">re</code>, <code class="language-plaintext highlighter-rouge">json</code>, etc.</li> <li> <strong>BM25 search API</strong>: <code class="language-plaintext highlighter-rouge">bm25_search(query, bm25, docids, k=20)</code> </li> <li> <strong>Document access</strong>: <code class="language-plaintext highlighter-rouge">get_doc_text(doc_id, corpus_dict)</code> </li> </ul> <p>It was quite amazing to see how creative the Root-LM was. From reading through the logs, it “felt” like it was freed from having to use these pre-defined search tools, one at a time. There were so many cool patterns, I’m including a few of my favorites below:</p> <h3 id="pattern-1-progressive-refinement-bm25--complex-filtering">Pattern 1: Progressive Refinement (BM25 + complex filtering)</h3> <p><strong>Task</strong>: Finding academic papers about educational technology published between 2011-2015 with multiple co-authors.</p> <p>In the system prompt, we provide research heuristics like “go broad and then narrow”. Sounds easy to do, but hard when the agent is bound to using search tools turn by turn. With code execution, it’s suddenly possible! The code below allows the agent to review 500 docs in 1.3 seconds. There’s something…magically pragmatic to see the LLM implement code to “count” the number of authors, to satisfy the search requirement. Not very elegant, but it works!</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">results</span> <span class="o">=</span> <span class="nf">bm25_search</span><span class="p">(</span>
<span class="sh">'</span><span class="s">article online learning educational technology platform teaching methods </span><span class="sh">'</span>
<span class="sh">'</span><span class="s">digital classroom 2010 2011 2012 2013 2014 2015 2016</span><span class="sh">'</span><span class="p">,</span>
<span class="n">bm25</span><span class="p">,</span>
<span class="n">docids</span><span class="p">,</span>
<span class="n">k</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">found_articles</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">doc_id</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
<span class="n">text</span> <span class="o">=</span> <span class="nf">get_doc_text</span><span class="p">(</span><span class="n">doc_id</span><span class="p">,</span> <span class="n">corpus_dict</span><span class="p">)</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">text</span><span class="p">:</span>
<span class="k">continue</span>

    <span class="c1"># Check for publication year between 2011 and 2015
</span>    <span class="n">pub_year</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">for</span> <span class="n">year</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">2011</span><span class="p">,</span> <span class="mi">2016</span><span class="p">):</span>
        <span class="k">if</span> <span class="nf">str</span><span class="p">(</span><span class="n">year</span><span class="p">)</span> <span class="ow">in</span> <span class="n">text</span><span class="p">:</span>
            <span class="n">pub_year</span> <span class="o">=</span> <span class="n">year</span>
            <span class="k">break</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">pub_year</span><span class="p">:</span>
        <span class="k">continue</span>

    <span class="c1"># Check for educational technology context
</span>    <span class="n">topic_keywords</span> <span class="o">=</span> <span class="p">[</span>
        <span class="sh">'</span><span class="s">online learning</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">student engagement</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">virtual classroom</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">educational platform</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">remote teaching</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">digital curriculum</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">assessment</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">pedagogy</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">learning outcomes</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">technology integration</span><span class="sh">'</span><span class="p">,</span>
    <span class="p">]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nf">any</span><span class="p">(</span><span class="n">keyword</span> <span class="ow">in</span> <span class="n">text</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">keyword</span> <span class="ow">in</span> <span class="n">topic_keywords</span><span class="p">):</span>
        <span class="k">continue</span>

    <span class="c1"># Attempt to count authors (&gt;2 required)
</span>    <span class="n">author_count_match</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">search</span><span class="p">(</span>
        <span class="sa">r</span><span class="sh">'</span><span class="s">(?:by|authors?[:\n])\s*([A-Z][a-z]+(?:\s[A-Z][a-z]+)?</span><span class="sh">'</span>
        <span class="sa">r</span><span class="sh">'</span><span class="s">(?:,\s*[A-Z][a-z]+(?:\s[A-Z][a-z]+)?){2,})</span><span class="sh">'</span><span class="p">,</span>
        <span class="n">text</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">author_count_match</span><span class="p">:</span>
        <span class="n">authors_list</span> <span class="o">=</span> <span class="n">author_count_match</span><span class="p">.</span><span class="nf">group</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span><span class="p">)</span>
        <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">authors_list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">found_articles</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span>
                <span class="p">{</span><span class="sh">'</span><span class="s">doc_id</span><span class="sh">'</span><span class="p">:</span> <span class="n">doc_id</span><span class="p">,</span> <span class="sh">'</span><span class="s">year</span><span class="sh">'</span><span class="p">:</span> <span class="n">pub_year</span><span class="p">,</span> <span class="sh">'</span><span class="s">authors_snippet</span><span class="sh">'</span><span class="p">:</span> <span class="n">author_count_match</span><span class="p">.</span><span class="nf">group</span><span class="p">(</span><span class="mi">0</span><span class="p">)}</span>
            <span class="p">)</span></code></pre></figure> <h3 id="pattern-2-adaptive-fallback-strategy">Pattern 2: Adaptive Fallback Strategy</h3> <p><strong>Task</strong>: Extracting an athlete’s height from a sports database with fallback to broader search.</p> <p>This pattern occurred a lot, the Root-LM was able to quickly test a hypothesis, but instead of waiting another turn to pivot, it adds a “self healing” fallback step to search more. Again, amusing to see it use code to do some derivation (m to cm) and math. (BrowseComp Plus has a lot of queries requiring derivations like “this institution was open for 671 days”, and the LLM has to compile lists of potential start/close dates and derive to see if it’s a match. Fun dataset!)</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">athlete_doc_id</span> <span class="o">=</span> <span class="sh">'</span><span class="s">doc12345</span><span class="sh">'</span>
<span class="n">athlete_text</span> <span class="o">=</span> <span class="nf">get_doc_text</span><span class="p">(</span><span class="n">athlete_doc_id</span><span class="p">,</span> <span class="n">corpus_dict</span><span class="p">)</span>

<span class="c1"># Try specific document first
</span>
<span class="n">height_pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="sh">'</span><span class="s">height:\s*(\d\.\d{2})\s*m</span><span class="sh">'</span>
<span class="n">height_match</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">search</span><span class="p">(</span><span class="n">height_pattern</span><span class="p">,</span> <span class="n">athlete_text</span><span class="p">,</span> <span class="n">re</span><span class="p">.</span><span class="n">IGNORECASE</span><span class="p">)</span>

<span class="k">if</span> <span class="n">height_match</span><span class="p">:</span>
<span class="n">height_m</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="n">height_match</span><span class="p">.</span><span class="nf">group</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">height_cm</span> <span class="o">=</span> <span class="n">height_m</span> <span class="n">_</span> <span class="mi">100</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Athlete</span><span class="sh">'</span><span class="s">s height: </span><span class="si">{</span><span class="n">height_cm</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> cm</span><span class="sh">"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Height information not found in doc12345. Expanding search.</span><span class="sh">"</span><span class="p">)</span> <span class="c1"># Fallback: broader search
</span><span class="n">results</span> <span class="o">=</span> <span class="nf">bm25_search</span><span class="p">(</span><span class="sh">'</span><span class="s">professional athlete height statistics</span><span class="sh">'</span><span class="p">,</span> <span class="n">bm25</span><span class="p">,</span> <span class="n">docids</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="k">for</span> <span class="n">doc_id</span><span class="p">,</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">results</span><span class="p">:</span>
<span class="n">text</span> <span class="o">=</span> <span class="nf">get_doc_text</span><span class="p">(</span><span class="n">doc_id</span><span class="p">,</span> <span class="n">corpus_dict</span><span class="p">)</span>
<span class="n">height_match</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">search</span><span class="p">(</span><span class="n">height_pattern</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">re</span><span class="p">.</span><span class="n">IGNORECASE</span><span class="p">)</span>
<span class="k">if</span> <span class="n">height_match</span><span class="p">:</span>
<span class="n">height_m</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="n">height_match</span><span class="p">.</span><span class="nf">group</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">height_cm</span> <span class="o">=</span> <span class="n">height_m</span> <span class="n">_</span> <span class="mi">100</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Athlete</span><span class="sh">'</span><span class="s">s height found in </span><span class="si">{</span><span class="n">doc_id</span><span class="si">}</span><span class="s">: </span><span class="si">{</span><span class="n">height_cm</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="s"> cm</span><span class="sh">"</span><span class="p">)</span>
<span class="k">break</span></code></pre></figure> <h3 id="pattern-3-parallel-information-gathering--sub-lm-compression">Pattern 3: Parallel Information Gathering + Sub-LM Compression</h3> <p><strong>Task</strong>: Comparing exhibition space and visitor capacity across multiple museums.</p> <p>The agent tested multiple hypotheses in parallel, and batched document retrieval. Retrieved 15 documents (14,797 characters) in a single execution, triggered Sub-LM compression, which condensed it to 1,630 characters (~9x reduction). In this case, the Sub-LM summary directly contained the correct answer.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">doc_ids_museum_a_area</span> <span class="o">=</span> <span class="nf">bm25_search</span><span class="p">(</span>
<span class="sh">'</span><span class="s">Metropolitan Museum exhibition space square feet</span><span class="sh">'</span><span class="p">,</span> <span class="n">bm25</span><span class="p">,</span> <span class="n">docids</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span>
<span class="p">)</span>
<span class="n">doc_ids_museum_b_area</span> <span class="o">=</span> <span class="nf">bm25_search</span><span class="p">(</span>
<span class="sh">'</span><span class="s">British Museum gallery area square feet</span><span class="sh">'</span><span class="p">,</span> <span class="n">bm25</span><span class="p">,</span> <span class="n">docids</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span>
<span class="p">)</span>
<span class="n">doc_ids_museum_c_capacity</span> <span class="o">=</span> <span class="nf">bm25_search</span><span class="p">(</span>
<span class="sh">'</span><span class="s">Louvre Museum daily visitor capacity</span><span class="sh">'</span><span class="p">,</span> <span class="n">bm25</span><span class="p">,</span> <span class="n">docids</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">doc_id</span> <span class="ow">in</span> <span class="n">doc_ids_museum_a_area</span><span class="p">:</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">[</span><span class="si">{</span><span class="n">doc_id</span><span class="si">}</span><span class="s">]: </span><span class="si">{</span><span class="nf">get_doc_text</span><span class="p">(</span><span class="n">doc_id</span><span class="p">,</span> <span class="n">corpus_dict</span><span class="p">)</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span> <span class="c1"># ... (repeat for other museums)</span></code></pre></figure> <h3 id="error-handling">Error handling</h3> <p>I did want to note that code execution was only successful 78% of the time, failures were typically due to overly complex regex patterns. In the case of failure, the error was passed back to the Root-LM, and triggered a retry that was typically successful.</p> <h3 id="sandbox-constraints">Sandbox Constraints</h3> <ul> <li>30-second timeout per execution (enforced via SIGALRM)</li> <li>Output truncation at 15,000 characters (~5,000 tokens) with intelligent line-boundary truncation</li> <li>Module whitelist: only <code class="language-plaintext highlighter-rouge">re</code> and <code class="language-plaintext highlighter-rouge">json</code> (no numpy, pandas, requests, etc.)</li> <li>No network access: no socket, urllib, requests, or any I/O modules</li> <li>No file system access: no <code class="language-plaintext highlighter-rouge">open()</code>, <code class="language-plaintext highlighter-rouge">os</code>, <code class="language-plaintext highlighter-rouge">pathlib</code>, or file operations</li> <li>Read-only corpus access: can read <code class="language-plaintext highlighter-rouge">corpus_dict</code>, <code class="language-plaintext highlighter-rouge">query_text</code>, BM25 index, and <code class="language-plaintext highlighter-rouge">docids</code> but cannot modify them</li> <li>Restricted builtins: only safe built-ins like <code class="language-plaintext highlighter-rouge">print</code>, <code class="language-plaintext highlighter-rouge">len</code>, <code class="language-plaintext highlighter-rouge">range</code>, type constructors – no <code class="language-plaintext highlighter-rouge">exec</code>, <code class="language-plaintext highlighter-rouge">eval</code>, <code class="language-plaintext highlighter-rouge">compile</code>, <code class="language-plaintext highlighter-rouge">__import__</code> (except a controlled <code class="language-plaintext highlighter-rouge">safe_import</code>)</li> </ul> <hr> <h2 id="architecture">Architecture</h2> <pre><code class="language-mermaid">sequenceDiagram
  participant User
  participant RootLM as Root-LM
  participant Retrieval as Retrieval Tools
  participant CodeExec as Code Executor
  participant SubLM as Sub-LM

  User-&gt;&gt;RootLM: Question

  alt Retrieval Path
    RootLM-&gt;&gt;Retrieval: Query
    Note over Retrieval: BM25, Regex,&lt;br/&gt;or Keyword Search
    Retrieval--&gt;&gt;SubLM: Documents

  else Code Execution Path
    RootLM-&gt;&gt;CodeExec: Python code
    Note over CodeExec: Sandboxed execution&lt;br/&gt;with corpus access
    CodeExec--&gt;&gt;SubLM: Execution results
  end

  SubLM--&gt;&gt;RootLM: Compressed summary + reflection

  loop Until confident or max iterations
    RootLM-&gt;&gt;RootLM: Select next action
  end

  RootLM--&gt;&gt;User: Final answer + citations
</code></pre> <hr> <h2 id="limitations">Limitations</h2> <p><strong>Small sample size</strong>: 20 queries x multiple runs is a good signal but not definitive. Scaling to the full 830-query benchmark is needed. <strong>Latency</strong>: Averaging 558 seconds (9.3 minutes) per query for hard cases. This works for research tasks but isn’t suitable for real-time applications.</p> <hr> <h2 id="future-directions">Future Directions</h2> <p>The natural next step is exploring memory systems for successful paths, and anti-patterns. For example, when the agent discovers that “progressive refinement” works for academic paper queries, it should remember and reuse this pattern. To me, this is a version of “continual learning” that motivated the series of blog posts.</p> <p>This aligns with Anthropic’s <a href="https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills" rel="external nofollow noopener" target="_blank">Agent Skills</a> work and the <a href="https://arxiv.org/pdf/2509.25140" rel="external nofollow noopener" target="_blank">Memory Reasoning Bank</a> paper - encoding successful reasoning traces and retrieval strategies as reusable knowledge.</p> <hr> <p><em>This work builds on <a href="https://alexzhang13.github.io/blog/2025/rlm/" rel="external nofollow noopener" target="_blank">Recursive Language Models</a> by Alex Zhang, Anthropic’s <a href="https://www.anthropic.com/engineering/code-execution-with-mcp" rel="external nofollow noopener" target="_blank">code execution research</a>, and the <a href="https://arxiv.org/html/2508.06600v1" rel="external nofollow noopener" target="_blank">BrowseComp Plus dataset</a>.</em></p> <p><em>Views are strictly my own. Experiments based only on public datasets. Code examples have been genericized to respect the BrowseComp Plus dataset policy (“BENCHMARK DATA SHOULD NEVER APPEAR AS PLAIN TEXT ONLINE”).</em></p> <p><em>Published: November 22, 2025</em></p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/recursive-language-models/">Recursive Language Models reduce context rot and 2.5× accuracy on BrowseComp‑Plus (at 2.6× latency)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/anti-patterns-as-guardrails/">Exploring Continuous Learning: Reasoning Bank + Recursive Language Models</a> </li> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/mermaid@10.7.0/dist/mermaid.min.js" integrity="sha256-TtLOdUA8mstPoO6sGvHIGx2ceXrrX4KgIItO06XOn8A=" crossorigin="anonymous"></script> <script defer src="/assets/js/mermaid-setup.js?38ca0a0126f7328d2d9a46bad640931f" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>